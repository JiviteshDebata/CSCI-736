# The Project Aims to explore Caution AI/ Explainable AI/ General AI

## The scope of the project is limited currently to the following visual comparisons as required

- A visual representation of interactions of various nerual networks at a lower dimensions .
- Analaysis of how those models might have a concept of "limits" of a model .
- A formal definition of what a limit might be and how weights, biases and limits can be defined .


## Environment and Setup

- The project uses conda environments and jyuptier notebooks heavily to make reports and analysis 
- A toy model with 2 input neurons , three hidden neurons and finally three ouput neurons are the center of all these experiments. 
- First pure random number with fixed ranges are generated and finally that is trained over the nueral network. 
- Similary the problem is transfered over to a visual task of selecting color of pixels.A data collector is custom made for this task. This allows us to make a comparison to "true"  intelligence or human intelligence. 
- Then with the findings.Its applied on models designed for the MNIST data set to find those points. 
- Evaluation all models gives us a domain wide idea r



## WIP

- MNIST utils.