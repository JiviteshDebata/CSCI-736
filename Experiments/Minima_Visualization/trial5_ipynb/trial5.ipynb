{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 1000\n  y sizes: 900\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 217\u001b[0m\n\u001b[0;32m    215\u001b[0m y, sum_of_inputs \u001b[39m=\u001b[39m pick_experiment(expar_number\u001b[39m=\u001b[39mexperiment,X\u001b[39m=\u001b[39mX, color_bias\u001b[39m=\u001b[39mcolor_bias, sum_of_inputs\u001b[39m=\u001b[39msum_of_inputs)\n\u001b[0;32m    216\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[1;32m--> 217\u001b[0m model\u001b[39m.\u001b[39;49mfit(X, y, epochs\u001b[39m=\u001b[39;49mepochs, verbose\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n\u001b[0;32m    220\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_plot\u001b[39m(weight_updates, bias_updates):\n\u001b[0;32m    221\u001b[0m     \u001b[39mfor\u001b[39;00m i, layer \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(model\u001b[39m.\u001b[39mlayers):\n",
      "File \u001b[1;32mc:\\Users\\johns\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\johns\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\data_adapter.py:1851\u001b[0m, in \u001b[0;36m_check_data_cardinality\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1844\u001b[0m     msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m  \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m sizes: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   1845\u001b[0m         label,\n\u001b[0;32m   1846\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\n\u001b[0;32m   1847\u001b[0m             \u001b[39mstr\u001b[39m(i\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(single_data)\n\u001b[0;32m   1848\u001b[0m         ),\n\u001b[0;32m   1849\u001b[0m     )\n\u001b[0;32m   1850\u001b[0m msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mMake sure all arrays contain the same number of samples.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1851\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 1000\n  y sizes: 900\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "TODO: Gather data for expariment 4 -> humans look at 2 blocks and asked if it is white, black, or grey\n",
    "TODO: Implement the S4 expariment\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "\n",
    "ei = \"\"\n",
    "cb = \"\"\n",
    "pvmax = \"\"\n",
    "pvmin = \"\"\n",
    "ep = \"\"\n",
    "ds = \"\"\n",
    "if (input(\"Do you wish to use the defaults? [Y/N]\") == \"N\"):\n",
    "    ei = input(\"Which Expariment do you wish to do? int [1 -> 4]\")\n",
    "    cb = input(\"what do you want as a color bias? int [0 -> inf]\")\n",
    "    pvmax = input(\"what is the maximum pixel value?\")\n",
    "    pvmin = input(\"what is the minimum pixel value?\")\n",
    "    ep = input(\"How many epochs?\")\n",
    "    ds = input(\"how many data points do you wish to train on?\")\n",
    "\n",
    "experiment = int(ei) if ei != \"\" else 4\n",
    "color_bias = int(cb) if cb != \"\" else 150\n",
    "pixel_val_max = int(pvmax) if pvmax != \"\" else 255\n",
    "pixel_val_min = int(pvmin) if pvmax != \"\" else 0\n",
    "\n",
    "epochs = int(ep) if ep != \"\" else 100\n",
    "data_size = int(ds) if ds != \"\" else 1000\n",
    "\n",
    "\n",
    "'''\n",
    "intersting setups:\n",
    "\n",
    "1.)\n",
    "experiment      = 1\n",
    "color_bias      = 150\n",
    "pixel_val_max   = 255\n",
    "pixel_val_min   = 0\n",
    "epochs          = 100\n",
    "data_size       = 1000\n",
    "\n",
    "2.)\n",
    "experiment      = 3\n",
    "color_bias      = 170\n",
    "pixel_val_max   = 255\n",
    "pixel_val_min   = 0\n",
    "epochs          = 100\n",
    "data_size       = 1000\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "# Define the neural network model\n",
    "model = Sequential([\n",
    "    Dense(3, activation='sigmoid', input_shape=(2,)),\n",
    "    Dense(3, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.01), loss='mse', metrics=['accuracy'])\n",
    "\n",
    "# Generate training data\n",
    "X = np.random.randint(pixel_val_min, pixel_val_max, (data_size, 2))\n",
    "\n",
    "'''Math defined, black, white, or grey'''\n",
    "def S1(X, n, input_tracker):\n",
    "    y = np.zeros((X.shape[0], 3))\n",
    "    answer_tracker = [0,0,0]\n",
    "    for i, (x1, x2) in enumerate(X):\n",
    "        answer_tracker = [0,0,0]\n",
    "        if (x1 + x2) < (2*pixel_val_min + n):\n",
    "            answer_tracker[0] = 1\n",
    "            y[i, 0] = 1\n",
    "        elif (x1 + x2) > (2*pixel_val_max - n):\n",
    "            answer_tracker[1] = 1\n",
    "            y[i, 1] = 1\n",
    "        else:\n",
    "            answer_tracker[2] = 1\n",
    "            y[i, 2] = 1\n",
    "        input_tracker = np.add(answer_tracker,input_tracker) \n",
    "    return y, input_tracker\n",
    "\n",
    "\n",
    "'''More restrictive Math defined, black, white, or grey'''\n",
    "def S2(X, n, input_tracker):\n",
    "    y = np.zeros((X.shape[0], 3))\n",
    "    answer_tracker = [0,0,0]\n",
    "    for i, (x1, x2) in enumerate(X):\n",
    "        answer_tracker = [0,0,0]\n",
    "        if x1 > x2 and x1 < (pixel_val_min+n):\n",
    "            answer_tracker[0] = 1\n",
    "            y[i, 0] = 1\n",
    "        elif x1 < x2 and x2 > (pixel_val_max - n):\n",
    "            answer_tracker[1] = 1\n",
    "            y[i, 1] = 1\n",
    "        else:\n",
    "            answer_tracker[2] = 1\n",
    "            y[i, 2] = 1\n",
    "        input_tracker = np.add(answer_tracker,input_tracker) \n",
    "    return y, input_tracker\n",
    "\n",
    "'''Math defined, black, white, or grey BUT every third answer is neither'''\n",
    "def S3(X, n, input_tracker):\n",
    "    y = np.zeros((X.shape[0], 3))\n",
    "    answer_tracker = [0,0,0]\n",
    "    counter = 0\n",
    "    for i, (x1, x2) in enumerate(X):\n",
    "        counter += 1\n",
    "        answer_tracker = [0,0,0]\n",
    "        if x1 + x2 < n and counter !=3:\n",
    "            answer_tracker[0] = 1\n",
    "            y[i, 0] = 1\n",
    "        elif x1 + x2 > n and counter != 3:\n",
    "            answer_tracker[1] = 1\n",
    "            y[i, 1] = 1\n",
    "        else:\n",
    "            answer_tracker[2] = 1\n",
    "            y[i, 2] = 1\n",
    "            counter = 0\n",
    "        input_tracker = np.add(answer_tracker,input_tracker) \n",
    "    return y, input_tracker\n",
    "\n",
    "# TODO: Gather the human defined data and finish this function\n",
    "'''Human defined, black, white, or grey'''\n",
    "# def S4(X, n, input_tracker):\n",
    "#     human_data, human_answers = __S4()\n",
    "#     y = np.zeros((X.shape[0], 3))\n",
    "#     answer_tracker = [0,0,0]\n",
    "#     for i in human_answers:\n",
    "#         answer_tracker = [0,0,0]\n",
    "#         if i[0] == 1:\n",
    "#             answer_tracker[0] = 1\n",
    "#             y[i, 0] = 1\n",
    "#         elif i[1] == 1:\n",
    "#             answer_tracker[1] = 1\n",
    "#             y[i, 1] = 1\n",
    "#         else:\n",
    "#             answer_tracker[2] = 1\n",
    "#             y[i, 2] = 1\n",
    "#         input_tracker = np.add(answer_tracker,input_tracker) \n",
    "#     return y, input_tracker\n",
    "\n",
    "\n",
    "\n",
    "def s4(folder_path):\n",
    "    def encode_colors(color):\n",
    "        if color == \"black\":\n",
    "            return [1, 0, 0]\n",
    "        elif color == \"grey\":\n",
    "            return [0, 1, 0]\n",
    "        else:\n",
    "            return [0, 0, 1]\n",
    "    # print(os.path.join(folder_path))\n",
    "    # Read JSON files\n",
    "    all_data = []\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith(\".json\"):\n",
    "            with open(os.path.join(folder_path, file_name), \"r\") as f:\n",
    "                file_data = json.load(f)\n",
    "                all_data.extend(file_data)\n",
    "\n",
    "    # Preprocess data\n",
    "    X = []\n",
    "    y = []\n",
    "    for data in all_data:\n",
    "        X.append([data[\"X1\"], data[\"X2\"]])\n",
    "        y.append(encode_colors(data[\"selectedColor\"]))\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    return X, y\n",
    "    \n",
    "# humanx,humany = s4(\"C:/Users\")\n",
    "\n",
    "# humanx,humany = s4(\"C:/Users/johns/Documents/NNandML/OpenSet/Project/Minima_Visualization/trial5_ipynb\")\n",
    "\n",
    "\n",
    "def pick_experiment(expar_number, X, color_bias, sum_of_inputs):\n",
    "    y = 0\n",
    "    if expar_number == 1:\n",
    "        y, sum_of_inputs = S1(X, color_bias, sum_of_inputs)\n",
    "    elif expar_number == 2:\n",
    "        y, sum_of_inputs = S2(X, color_bias, sum_of_inputs)\n",
    "    elif expar_number == 3:\n",
    "        y, sum_of_inputs = S3(X, color_bias, sum_of_inputs)\n",
    "    elif expar_number == 4:\n",
    "        y, sum_of_inputs = s4(\"C:/Users/johns/Documents/NNandML/OpenSet/Project/Minima_Visualization/trial5_ipynb\")\n",
    "    return y, sum_of_inputs\n",
    "\n",
    "sum_of_inputs = [0,0,0]\n",
    "# human_data, human_answers = \n",
    "y, sum_of_inputs = pick_experiment(expar_number=experiment,X=X, color_bias=color_bias, sum_of_inputs=sum_of_inputs)\n",
    "# Train the model\n",
    "model.fit(X, y, epochs=epochs, verbose=2)\n",
    "\n",
    "\n",
    "def create_plot(weight_updates, bias_updates):\n",
    "    for i, layer in enumerate(model.layers):\n",
    "        weights = layer.get_weights()\n",
    "        weights[0] += weight_updates[i]\n",
    "        weights[1] += bias_updates[i]\n",
    "        layer.set_weights(weights)\n",
    "\n",
    "    x_vals = np.linspace(pixel_val_min, pixel_val_max, 50)\n",
    "    y_vals = np.linspace(pixel_val_min, pixel_val_max, 50)\n",
    "    X_grid, Y_grid = np.meshgrid(x_vals, y_vals)\n",
    "    input_grid = np.column_stack((X_grid.ravel(), Y_grid.ravel()))\n",
    "    output_grid = model.predict(input_grid)\n",
    "\n",
    "    fig = make_subplots(rows=1, cols=4, specs=[[{'type': 'surface'}, {'type': 'surface'}, {'type': 'surface'}, {'type': 'scatter3d'}]])\n",
    "\n",
    "    trace1 = go.Surface(x=X_grid, y=Y_grid, z=output_grid[:, 0].reshape(X_grid.shape), showscale=False,\n",
    "                        hovertemplate=\"Input Neuron 1 : %{x} <br>Input Neuron 2 : %{y} <br>Output Neuron 1: %{z} <br> Output Neuron 2: %{customdata[0]} <br>Output Neuron 3: %{customdata[1]}<extra></extra>\",\n",
    "                        customdata=np.column_stack((output_grid[:, 1], output_grid[:, 2])).reshape(X_grid.shape[0], X_grid.shape[1], 2))\n",
    "                        # customdata=np.column_stack((output_grid[:, 1], output_grid[:, 2], np.ones_like(output_grid[:, 0]) * 42, np.ones_like(output_grid[:, 0]) * 99)).reshape(X_grid.shape[0], X_grid.shape[1], 4))\n",
    "\n",
    "        \n",
    "    trace2 = go.Surface(x=X_grid, y=Y_grid, z=output_grid[:, 1].reshape(X_grid.shape), showscale=False,\n",
    "                        hovertemplate=\"Input Neuron 1: %{x}, Input Neuron 2: %{y}<br>Output Neuron 1: %{customdata[0]}<br>Output Neuron 2: %{z}<br>Output Neuron 3: %{customdata[1]}<extra></extra>\",\n",
    "                        customdata=np.column_stack((output_grid[:, 0], output_grid[:, 2])).reshape(X_grid.shape[0], X_grid.shape[1], 2))\n",
    "    trace3 = go.Surface(x=X_grid, y=Y_grid, z=output_grid[:, 2].reshape(X_grid.shape), showscale=False,\n",
    "                        hovertemplate=\"Input Neuron 1: %{x}, Input Neuron 2: %{y}<br>Output Neuron 1: %{customdata[0]}<br>Output Neuron 2: %{customdata[1]}<br>Output Neuron 3: %{z}<extra></extra>\",\n",
    "                        customdata=np.column_stack((output_grid[:, 0], output_grid[:, 1])).reshape(X_grid.shape[0], X_grid.shape[1], 2))\n",
    "    \n",
    "    trace4 = go.Scatter3d(x=input_grid[:, 0], y=input_grid[:, 1], z=output_grid[:, 0], mode='markers', marker=dict(size=3, color='red'), name='Output Neuron 1',\n",
    "                        hovertemplate=\"Input Neuron 1: %{x}<br> Input Neuron 2: %{y}<br> Output Neuron 1: %{z}\")\n",
    "\n",
    "\n",
    "\n",
    "    trace5 = go.Scatter3d(x=input_grid[:, 0], y=input_grid[:, 1], z=output_grid[:, 1], mode='markers', marker=dict(size=3, color='green'), name='Output Neuron 2',\n",
    "                        hovertemplate=\"Input Neuron 1: %{x}<br> Input Neuron 2: %{y}<br> Output Neuron 2: %{z}\")\n",
    "    \n",
    "    trace6 = go.Scatter3d(x=input_grid[:, 0], y=input_grid[:, 1], z=output_grid[:, 2], mode='markers', marker=dict(size=3, color='blue'), name='Output Neuron 3',\n",
    "                        hovertemplate=\"Input Neuron 1: %{x}<br> Input Neuron 2: %{y}<br> Output Neuron 2: %{z}\")\n",
    "\n",
    "\n",
    "    fig.add_trace(trace1, row=1, col=1)\n",
    "    fig.add_trace(trace2, row=1, col=2)\n",
    "    fig.add_trace(trace3, row=1, col=3)\n",
    "    \n",
    "    fig.add_trace(trace4, row=1, col=4)\n",
    "    fig.add_trace(trace5, row=1, col=4)\n",
    "    fig.add_trace(trace6, row=1, col=4)\n",
    "    \n",
    "    min_z = min(output_grid.min(), output_grid.min(), output_grid.min())\n",
    "    max_z = min(max(output_grid.max(), output_grid.max(), output_grid.max()),1) \n",
    "    \n",
    "    fig.update_layout(hovermode=\"x unified\", hoverdistance=50,\n",
    "                      scene=dict(xaxis_title=\"Input Neuron 1\", yaxis_title=\"Input Neuron 2\", zaxis_title=\"Output Neuron 1\", zaxis_range=[min_z, max_z]),\n",
    "                      scene2=dict(xaxis_title=\"Input Neuron 1\", yaxis_title=\"Input Neuron 2\", zaxis_title=\"Output Neuron 2\",  zaxis_range=[min_z, max_z]),\n",
    "                      scene3=dict(xaxis_title=\"Input Neuron 1\", yaxis_title=\"Input Neuron 2\", zaxis_title=\"Output Neuron 3\", zaxis_range=[min_z, max_z]),\n",
    "                      scene4=dict(xaxis_title=\"Input Neuron 1\", yaxis_title=\"Input Neuron 2\", zaxis_title=\"Output Neurons\"))\n",
    "\n",
    "    return fig\n",
    "\n",
    "def plot(weight_update, bias_update):\n",
    "    weight_updates = [np.ones((2, 3)) * weight_update, np.ones((3, 3)) * weight_update]\n",
    "    bias_updates = [np.ones(3) * bias_update, np.ones(3) * bias_update]\n",
    "    fig = create_plot(weight_updates, bias_updates)\n",
    "    fig.show()\n",
    "\n",
    "weight_slider = widgets.FloatSlider(min=-1, max=1, step=0.1, value=0, description=\"Weight Update\")\n",
    "bias_slider = widgets.FloatSlider(min=-1, max=1, step=0.1, value=0, description=\"Bias Update\")\n",
    "\n",
    "print(\"These were \",sum_of_inputs, \" of each example\")\n",
    "widgets.interact(plot, weight_update=weight_slider, bias_update=bias_slider)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_hw_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
